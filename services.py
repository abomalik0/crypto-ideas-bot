import time
import json
import threading
from datetime import datetime

import config
from analysis_engine import (
    format_analysis,
    format_market_report,
    format_risk_test,
    format_weekly_ai_report,
    format_ai_alert,
    get_market_metrics_cached,
    evaluate_risk_level,
    detect_alert_condition,
)

SNAPSHOT_PATH = "snapshot.json"


# ==============================
#   Snapshot (Warm Start)
# ==============================

def load_snapshot():
    """ØªØ­Ù…ÙŠÙ„ Snapshot Ø®ÙÙŠÙ Ø¹Ù†Ø¯ Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ø³ÙŠØ±ÙØ± Ù„ØªØ³Ø±ÙŠØ¹ Ø£ÙˆÙ„ Ø±Ø¯."""
    try:
        with open(SNAPSHOT_PATH, "r", encoding="utf-8") as f:
            data = json.load(f)

        mm = data.get("MARKET_METRICS_CACHE")
        if isinstance(mm, dict):
            config.MARKET_METRICS_CACHE.update(mm)

        rt = data.get("REALTIME_CACHE")
        if isinstance(rt, dict):
            for k, v in rt.items():
                if k in config.REALTIME_CACHE and (
                    isinstance(v, (str, int, float)) or v is None
                ):
                    config.REALTIME_CACHE[k] = v

        config.LAST_ALERT_REASON = data.get("LAST_ALERT_REASON")
        config.LAST_WEEKLY_SENT_DATE = data.get("LAST_WEEKLY_SENT_DATE")
        config.logger.info("Warm-start snapshot loaded successfully.")
    except FileNotFoundError:
        config.logger.info("No snapshot file found, starting cold.")
    except Exception as e:
        config.logger.exception("Failed to load snapshot: %s", e)


_last_snapshot_save_ts = 0.0


def save_snapshot():
    """Ø­ÙØ¸ Snapshot Ø®ÙÙŠÙ Ø¯ÙˆØ±Ù‰ Ù„Ø³Ø±Ø¹Ø© Ø§Ù„Ø±ÙŠØ³ØªØ§Ø±Øª."""
    global _last_snapshot_save_ts
    now = time.time()
    if now - _last_snapshot_save_ts < 30:
        return  # ÙƒÙ„ 30 Ø«Ø§Ù†ÙŠØ© ÙƒØ­Ø¯ Ø£Ø¯Ù†Ù‰

    snap = {
        "MARKET_METRICS_CACHE": config.MARKET_METRICS_CACHE,
        "REALTIME_CACHE": {
            k: v
            for k, v in config.REALTIME_CACHE.items()
            if isinstance(v, (str, int, float)) or v is None
        },
        "LAST_ALERT_REASON": config.LAST_ALERT_REASON,
        "LAST_WEEKLY_SENT_DATE": config.LAST_WEEKLY_SENT_DATE,
        "time": datetime.utcnow().isoformat(timespec="seconds"),
    }
    try:
        with open(SNAPSHOT_PATH, "w", encoding="utf-8") as f:
            json.dump(snap, f, ensure_ascii=False, indent=2)
        _last_snapshot_save_ts = now
    except Exception as e:
        config.logger.exception("Failed to save snapshot: %s", e)


# ==============================
#   ÙƒØ§Ø´ Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„
# ==============================

def get_cached_response(key: str, builder):
    """
    Ù„Ùˆ ÙÙ‰ Ø±Ø¯ Ø¬Ø§Ù‡Ø² Ø­Ø¯ÙŠØ« ÙÙ‰ REALTIME_CACHE â†’ Ø§Ø³ØªØ®Ø¯Ù…Ù‡.
    Ù„Ùˆ Ù„Ø£ â†’ Ø§Ø¨Ù†Ù Ø§Ù„Ø±Ø¯ Ø¨Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¹Ø§Ø¯ÙŠØ©.
    """
    try:
        now = time.time()
        last_update = config.REALTIME_CACHE.get("last_update")
        cached_value = config.REALTIME_CACHE.get(key)

        ttl = getattr(config, "REALTIME_TTL_SECONDS", 15)

        if cached_value and last_update and (now - last_update) <= ttl:
            return cached_value

        return builder()
    except Exception as e:
        config.logger.exception("get_cached_response error for %s: %s", key, e)
        return builder()


# ==============================
#   Ù…Ø­Ø±Ùƒ Real-Time
# ==============================

def realtime_engine_loop():
    """
    Ù…Ø­Ø±Ùƒ Real-Time:
    - ÙŠØ¬Ø¯Ø¯ ØªØ­Ù„ÙŠÙ„ BTC / Ø§Ù„Ø³ÙˆÙ‚ / Ø§Ù„Ù…Ø®Ø§Ø·Ø± ÙƒÙ„ Ø¹Ø¯Ø© Ø«ÙˆØ§Ù†Ù‰.
    - ÙŠØ¨Ù†Ù‰ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹Ù‰ Ø¨Ø´ÙƒÙ„ Ø¯ÙˆØ±Ù‰ (Ù„Ù…Ù†Ø¹ Ø§Ù„Ø¶ØºØ·).
    - ÙŠØ¨Ù†Ù‰ Ù†Øµ Ø§Ù„ØªØ­Ø°ÙŠØ± Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ Ø¨Ø³Ø±Ø¹Ø© Ø¹Ù†Ø¯ Ø§Ù„Ø§Ø³ØªØ¯Ø¹Ø§Ø¡.
    """
    config.logger.info("Realtime engine loop started.")
    while True:
        try:
            now = time.time()

            # ØªØ­Ù„ÙŠÙ„Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ©
            btc_msg = format_analysis("BTCUSDT")
            market_msg = format_market_report()
            risk_msg = format_risk_test()

            # ØªÙ‚Ø±ÙŠØ± Ø£Ø³Ø¨ÙˆØ¹Ù‰ (ÙƒÙ„ 10 Ø¯Ù‚Ø§Ø¦Ù‚ Ø¥Ø¹Ø§Ø¯Ø© Ø¨Ù†Ø§Ø¡)
            weekly_msg = config.REALTIME_CACHE.get("weekly_report")
            last_weekly_build = config.REALTIME_CACHE.get("weekly_built_at") or 0.0
            if not weekly_msg or (now - last_weekly_build) > 600:
                weekly_msg = format_weekly_ai_report()
                config.REALTIME_CACHE["weekly_built_at"] = now

            # Ù†Øµ ØªØ­Ø°ÙŠØ± Ø£Ø³Ø§Ø³Ù‰ (ÙŠØ³ØªØ®Ø¯Ù…Ù‡ maybe_send_market_alert)
            alert_msg = config.REALTIME_CACHE.get("alert_text")
            last_alert_build = config.REALTIME_CACHE.get("alert_built_at") or 0.0

            metrics = get_market_metrics_cached()
            if metrics:
                risk = evaluate_risk_level(
                    metrics["change_pct"], metrics["volatility_score"]
                )
                reason = detect_alert_condition(metrics, risk)
            else:
                risk = None
                reason = None

            # Ù„Ùˆ ÙÙ‰ Ø³Ø¨Ø¨ ØªØ­Ø°ÙŠØ± Ø£Ùˆ Ù…Ø± ÙˆÙ‚Øª Ø·ÙˆÙŠÙ„ â†’ Ù†Ø¨Ù†Ù‰ Ù†Øµ Ø¬Ø¯ÙŠØ¯
            if reason or not alert_msg or (now - last_alert_build) > 60:
                # Ù‡Ù†Ø§ Ø¨Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„ÙÙˆØ±Ù…Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù… Ø§Ù„Ù„Ù‰ ÙÙ‰ analysis_engine
                alert_msg = format_ai_alert()
                config.REALTIME_CACHE["alert_built_at"] = now

            config.REALTIME_CACHE.update(
                {
                    "btc_analysis": btc_msg,
                    "market_report": market_msg,
                    "risk_test": risk_msg,
                    "weekly_report": weekly_msg,
                    "alert_text": alert_msg,
                    "last_update": now,
                }
            )

            config.LAST_REALTIME_TICK = now
            save_snapshot()
            time.sleep(5)
        except Exception as e:
            config.logger.exception("Error in realtime engine loop: %s", e)
            time.sleep(5)


# ==============================
#   Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹Ù‰
# ==============================

def send_weekly_report_to_all_chats() -> list[int]:
    """
    ÙŠØ¨Ø¹Øª Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹Ù‰ Ù„ÙƒÙ„ Ø§Ù„Ø´Ø§ØªØ§Øª Ø§Ù„Ù…Ø³Ø¬Ù‘Ù„Ø© ÙÙ‰ KNOWN_CHAT_IDS.
    """
    report = get_cached_response("weekly_report", format_weekly_ai_report)
    sent_to: list[int] = []

    for cid in list(config.KNOWN_CHAT_IDS):
        try:
            config.send_message(cid, report)
            sent_to.append(cid)
        except Exception as e:
            config.logger.exception("Error sending weekly report to %s: %s", cid, e)

    config.logger.info("weekly_ai_report sent to chats: %s", sent_to)
    return sent_to


# ==============================
#   Helper: ØªÙ‚Ø¯ÙŠØ± Ù…Ø¯Ù‰ Ø§Ù„Ø­Ø±ÙƒØ©
# ==============================

def _estimate_expected_move_range(metrics, risk) -> dict:
    """
    ØªÙ‚Ø¯ÙŠØ± ØªÙ‚Ø±ÙŠØ¨Ù‰ (ØªØ¹Ù„ÙŠÙ…Ù‰) Ù„Ù…Ø¯Ù‰ Ø§Ù„Ù‡Ø¨ÙˆØ·/Ø§Ù„ØµØ¹ÙˆØ¯ Ø§Ù„Ù…Ø­ØªÙ…Ù„
    Ø¹Ø´Ø§Ù† Ù†Ø¶ÙŠÙÙ‡ ÙÙ‰ Ø§Ù„ØªØ­Ø°ÙŠØ± (Ù…Ù†Ø·Ù‚Ø© Ø³Ø¹Ø±ÙŠØ© ØªÙ‚Ø±ÙŠØ¨ÙŠØ©).
    """
    price = metrics.get("price") or 0
    change = float(metrics.get("change_pct") or 0)
    vol = float(metrics.get("volatility_score") or 0)
    rng = float(metrics.get("range_pct") or 0)

    if price <= 0:
        return {"min_price": None, "max_price": None, "move_dir": "flat"}

    # Ø§ØªØ¬Ø§Ù‡ Ø£Ø³Ø§Ø³Ù‰
    move_dir = "down" if change < 0 else "up" if change > 0 else "flat"

    # severity score ØªÙ‚Ø±ÙŠØ¨ÙŠØ©
    severity_score = abs(change) * 2.0 + vol * 0.5 + rng * 0.7
    level = risk.get("level") if isinstance(risk, dict) else None
    if level == "high":
        severity_score += 15
    elif level == "medium":
        severity_score += 5

    # Ù†Ø­ÙˆÙ„Ù‡Ø§ Ù„Ù†Ø³Ø¨Ø© Ø­Ø±ÙƒØ© Ø¥Ø¶Ø§ÙÙŠØ© Ù…Ø­ØªÙ…Ù„Ø©
    base_move = max(0.5, min(15.0, abs(change) * 0.6 + rng * 0.4 + severity_score * 0.05))

    # Ù†Ø­Ø¯Ø¯ Ù†Ø·Ø§Ù‚ (Ù…Ø­Ø§ÙØ¸ Ø´ÙˆÙŠØ©)
    if move_dir == "down":
        max_drop = min(30.0, base_move * 1.6)
        min_drop = max(2.0, base_move * 0.6)
        max_price = price * (1 - min_drop / 100.0)
        min_price = price * (1 - max_drop / 100.0)
    elif move_dir == "up":
        max_up = min(30.0, base_move * 1.6)
        min_up = max(2.0, base_move * 0.6)
        min_price = price * (1 + min_up / 100.0)
        max_price = price * (1 + max_up / 100.0)
    else:
        # Ù„Ùˆ Ø­Ø±ÙƒØ© Ø¬Ø§Ù†Ø¨ÙŠØ© ØªÙ‚Ø±ÙŠØ¨Ù‹Ø§
        band = min(8.0, rng * 0.8 + 3)
        min_price = price * (1 - band / 100.0)
        max_price = price * (1 + band / 100.0)

    return {
        "min_price": round(min_price),
        "max_price": round(max_price),
        "move_dir": move_dir,
        "severity_score": round(severity_score, 1),
    }


def _build_expected_move_note(metrics, risk) -> str:
    """ÙŠØ¨Ù†Ù‰ Ù†Øµ Ø¹Ø±Ø¨Ù‰ Ø¨Ø³ÙŠØ· Ù…Ù† ØªÙ‚Ø¯ÙŠØ± Ù…Ø¯Ù‰ Ø§Ù„Ø­Ø±ÙƒØ©."""
    est = _estimate_expected_move_range(metrics, risk)
    if not est["min_price"] or not est["max_price"]:
        return ""

    price = metrics.get("price") or 0
    move_dir = est["move_dir"]
    min_p = f"{est['min_price']:,}"
    max_p = f"{est['max_price']:,}"

    if move_dir == "down":
        return (
            f"\n\nğŸ“‰ <b>ØªÙ‚Ø¯ÙŠØ± Ù†Ø·Ø§Ù‚ Ø§Ù„Ù‡Ø¨ÙˆØ· Ø§Ù„Ù…Ø­ØªÙ…Ù„ (ØªØ¹Ù„ÙŠÙ…Ù‰ØŒ ØºÙŠØ± Ù…Ø¶Ù…ÙˆÙ†):</b>\n"
            f"â€¢ ÙÙ‰ Ø­Ø§Ù„Ø© Ø§Ø³ØªÙ…Ø±Ø§Ø± Ù†ÙØ³ Ø§Ù„Ø³Ù„ÙˆÙƒ Ø§Ù„Ø¨ÙŠØ¹Ù‰ØŒ Ù‚Ø¯ ÙŠÙ…ØªØ¯ Ø§Ù„Ù‡Ø¨ÙˆØ· Ø¨Ø´ÙƒÙ„ ØªÙ‚Ø±ÙŠØ¨Ù‰ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø¨ÙŠÙ† ~<code>{min_p}$</code> Ùˆ ~<code>{max_p}$</code>.\n"
            f"â€¢ Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„Ù‰ ØªÙ‚Ø±ÙŠØ¨Ù‹Ø§: <code>{price:,.0f}$</code> â€” Ø§Ø³ØªØ®Ø¯Ù… Ù‡Ø°Ù‡ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… ÙƒÙ…Ø±Ø¬Ø¹ ØªÙ‚Ø¯ÙŠØ±Ù‰ ÙÙ‚Ø· Ù…Ø¹ Ø¥Ø¯Ø§Ø±Ø© Ù…Ø®Ø§Ø·Ø± ØµØ§Ø±Ù…Ø©."
        )
    elif move_dir == "up":
        return (
            f"\n\nğŸ“ˆ <b>ØªÙ‚Ø¯ÙŠØ± Ù†Ø·Ø§Ù‚ Ø§Ù„ØµØ¹ÙˆØ¯ Ø§Ù„Ù…Ø­ØªÙ…Ù„ (ØªØ¹Ù„ÙŠÙ…Ù‰ØŒ ØºÙŠØ± Ù…Ø¶Ù…ÙˆÙ†):</b>\n"
            f"â€¢ ÙÙ‰ Ø­Ø§Ù„Ø© Ø§Ø³ØªÙ…Ø±Ø§Ø± Ø§Ù„Ø²Ø®Ù… Ø§Ù„ØµØ§Ø¹Ø¯ØŒ Ù‚Ø¯ ÙŠÙ…ØªØ¯ Ø§Ù„ØµØ¹ÙˆØ¯ Ø¨Ø´ÙƒÙ„ ØªÙ‚Ø±ÙŠØ¨Ù‰ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø¨ÙŠÙ† ~<code>{min_p}$</code> Ùˆ ~<code>{max_p}$</code>.\n"
            f"â€¢ Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„Ù‰ ØªÙ‚Ø±ÙŠØ¨Ù‹Ø§: <code>{price:,.0f}$</code> â€” Ø§Ù„Ø£Ø±Ù‚Ø§Ù… ØªÙ‚Ø±ÙŠØ¨ÙŠØ© ÙˆÙ„ÙŠØ³Øª Ø¶Ù…Ø§Ù†Ù‹Ø§."
        )
    else:
        return (
            f"\n\nğŸ” <b>Ù†Ø·Ø§Ù‚ ØªØ°Ø¨Ø°Ø¨ ØªÙ‚Ø¯ÙŠØ±Ù‰ (ØªØ¹Ù„ÙŠÙ…Ù‰ØŒ ØºÙŠØ± Ù…Ø¶Ù…ÙˆÙ†):</b>\n"
            f"â€¢ Ø§Ù„Ø³ÙˆÙ‚ Ù‚Ø¯ ÙŠØªØ­Ø±Ùƒ Ø¯Ø§Ø®Ù„ Ù†Ø·Ø§Ù‚ ØªÙ‚Ø±ÙŠØ¨Ù‰ Ø¨ÙŠÙ† ~<code>{min_p}$</code> Ùˆ ~<code>{max_p}$</code> ÙÙ‰ Ø­Ø§Ù„Ø© Ø§Ø³ØªÙ…Ø±Ø§Ø± Ù†ÙØ³ Ù†Ù…Ø· Ø§Ù„Ø­Ø±ÙƒØ©.\n"
            f"â€¢ ÙŠÙÙØ¶Ù„ Ø§Ù†ØªØ¸Ø§Ø± ÙƒØ³Ø± ÙˆØ§Ø¶Ø­ Ø®Ø§Ø±Ø¬ Ù‡Ø°Ø§ Ø§Ù„Ù†Ø·Ø§Ù‚ Ù‚Ø¨Ù„ Ù‚Ø±Ø§Ø±Ø§Øª Ø¹Ø¯ÙˆØ§Ù†ÙŠØ©."
        )


# ==============================
#   Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ­Ø°ÙŠØ± Ø§Ù„Ø°ÙƒÙ‰
# ==============================

def maybe_send_market_alert(source: str = "cron") -> dict:
    """
    Ù†Ø¸Ø§Ù… ØªØ­Ø°ÙŠØ± Ø°ÙƒÙ‰:
    - ÙŠÙ‚Ø±Ø£ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø³ÙˆÙ‚ Ù…Ù† Ø§Ù„ÙƒØ§Ø´.
    - ÙŠØ­Ø¯Ø¯ Ù‡Ù„ ÙÙ‰ ÙˆØ¶Ø¹ Ø­Ø³Ø§Ø³ ÙØ¹Ù„Ø§Ù‹ ÙˆÙ„Ø§ Ù„Ø£ (detect_alert_condition).
    - ÙŠÙ…Ù†Ø¹ Ø§Ù„ØªÙƒØ±Ø§Ø± Ø§Ù„Ù…Ø²Ø¹Ø¬ (cooldown Ø­Ø³Ø¨ Ø´Ø¯Ø© Ø§Ù„ÙˆØ¶Ø¹).
    - Ù„Ùˆ ÙÙ‰ ØªØ­Ø°ÙŠØ± Ø¬Ø¯ÙŠØ¯ â†’ ÙŠØ¨Ø¹Øª Ù„Ù„Ø£Ø¯Ù…Ù† ÙˆÙƒÙ„ Ø§Ù„Ø´Ø§ØªØ§Øª Ø§Ù„Ù…Ø³Ø¬Ù„Ø©.
    """
    metrics = get_market_metrics_cached()
    if not metrics:
        reason = "metrics_failed"
        now_iso = datetime.utcnow().isoformat(timespec="seconds")
        config.LAST_AUTO_ALERT_INFO = {
            "time": now_iso,
            "reason": reason,
            "sent": False,
            "source": source,
        }
        config.logger.warning("maybe_send_market_alert: cannot fetch metrics")
        return {
            "ok": False,
            "alert_sent": False,
            "reason": reason,
        }

    change = float(metrics.get("change_pct") or 0)
    vol = float(metrics.get("volatility_score") or 0)
    rng = float(metrics.get("range_pct") or 0)

    risk = evaluate_risk_level(change, vol)
    reason = detect_alert_condition(metrics, risk)

    now = time.time()
    now_iso = datetime.utcnow().isoformat(timespec="seconds")

    if not reason:
        # Ù…ÙÙŠØ´ ÙˆØ¶Ø¹ ØºÙŠØ± Ø·Ø¨ÙŠØ¹Ù‰ â†’ reset
        if config.LAST_ALERT_REASON is not None:
            config.logger.info("maybe_send_market_alert: market normal again â†’ reset alert state.")
        config.LAST_ALERT_REASON = None
        config.LAST_AUTO_ALERT_INFO = {
            "time": now_iso,
            "reason": "no_alert",
            "sent": False,
            "source": source,
        }
        return {
            "ok": True,
            "alert_sent": False,
            "reason": "no_alert",
        }

    # Ø­Ø³Ø§Ø¨ Ø´Ø¯Ø© Ø§Ù„ÙˆØ¶Ø¹ Ù„ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù€ cooldown
    severity_score = abs(change) * 2.0 + vol * 0.6 + rng * 0.8
    level = risk.get("level")
    if level == "high":
        severity_score += 20
    elif level == "medium":
        severity_score += 8

    # throttle / cooldown
    if severity_score >= 90:
        cooldown = 5 * 60    # Ø¹Ù†ÙŠÙ Ø¬Ø¯Ù‹Ø§ â†’ Ù…Ù…ÙƒÙ† ØªÙ†Ø¨ÙŠÙ‡ ÙƒÙ„ 5 Ø¯Ù‚Ø§Ø¦Ù‚
    elif severity_score >= 65:
        cooldown = 10 * 60   # Ù‚ÙˆÙ‰
    elif severity_score >= 40:
        cooldown = 20 * 60   # Ù…ØªÙˆØ³Ø·
    else:
        cooldown = 40 * 60   # Ø¶Ø¹ÙŠÙ â†’ Ù†Ø®ÙÙ‘Ù Ø§Ù„ØªÙ†Ø¨ÙŠÙ‡Ø§Øª

    last_info = config.LAST_AUTO_ALERT_INFO or {}
    last_reason = config.LAST_ALERT_REASON
    last_ts = float(last_info.get("ts") or 0)

    if last_reason == reason and (now - last_ts) < cooldown:
        # Ù†ÙØ³ Ø§Ù„Ø³Ø¨Ø¨ ÙˆÙ„Ø³Ù‡ ÙÙ‰ ÙØªØ±Ø© Ø§Ù„Ù€ cooldown â†’ Ù…Ù†Ø¨Ø¹ØªØ´ ØªØ§Ù†Ù‰
        remaining = int(cooldown - (now - last_ts))
        config.logger.info(
            "maybe_send_market_alert: throttled duplicate alert. reason=%s remaining=%ss",
            reason,
            remaining,
        )
        config.LAST_AUTO_ALERT_INFO = {
            "time": now_iso,
            "reason": "duplicate",
            "sent": False,
            "source": source,
            "ts": now,
            "cooldown": cooldown,
            "severity_score": round(severity_score, 1),
            "base_reason": reason,
        }
        return {
            "ok": True,
            "alert_sent": False,
            "reason": "duplicate",
            "cooldown_remaining": remaining,
        }

    # ÙˆØµÙ„Ù†Ø§ Ù‡Ù†Ø§ â†’ Ù„Ø§Ø²Ù… Ù†Ø¨Ø¹Øª ØªØ­Ø°ÙŠØ± Ø¬Ø¯ÙŠØ¯ ÙØ¹Ù„Ø§Ù‹
    base_alert = config.REALTIME_CACHE.get("alert_text") or format_ai_alert()
    extra_note = _build_expected_move_note(metrics, risk)
    final_alert_text = base_alert + extra_note

    sent_to = []

    # Ù†ØªØ£ÙƒØ¯ Ø§Ù„Ø£Ø¯Ù…Ù† Ø¶Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©
    all_chats = set(config.KNOWN_CHAT_IDS)
    all_chats.add(config.ADMIN_CHAT_ID)

    for cid in list(all_chats):
        try:
            # Ù…Ù…ÙƒÙ† Ù†Ø®Ù„Ù‰ ØºÙŠØ± Ø§Ù„Ø£Ø¯Ù…Ù† silent Ù„Ùˆ Ø§Ù„Ù…Ø®Ø§Ø·Ø±Ø© Ù…Ø´ high
            silent = (cid != config.ADMIN_CHAT_ID and level != "high")
            config.send_message(cid, final_alert_text, silent=silent)
            sent_to.append(cid)
        except Exception as e:
            config.logger.exception("Error sending auto alert to %s: %s", cid, e)

    config.LAST_ALERT_REASON = reason
    config.LAST_AUTO_ALERT_INFO = {
        "time": now_iso,
        "reason": reason,
        "sent": True,
        "source": source,
        "ts": now,
        "cooldown": cooldown,
        "severity_score": round(severity_score, 1),
        "sent_to": sent_to,
        "price": metrics.get("price"),
        "change_pct": change,
        "range_pct": rng,
        "volatility_score": vol,
        "risk_level": level,
    }
    config.logger.info(
        "maybe_send_market_alert: NEW alert sent! reason=%s severity=%.1f to=%s",
        reason,
        severity_score,
        sent_to,
    )

    # ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ­Ø°ÙŠØ±Ø§Øª (Ù„Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…)
    try:
        config.add_alert_history(
            source or "auto",
            reason,
            price=metrics.get("price"),
            change=change,
        )
    except Exception:
        # Ù„Ùˆ Ø§Ù„Ø¯Ø§Ù„Ø© Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙ‰ config Ø£Ùˆ util ØªØ§Ù†Ù‰
        try:
            from config import add_alert_history as _add_hist  # type: ignore
            _add_hist(
                source or "auto",
                reason,
                price=metrics.get("price"),
                change=change,
            )
        except Exception as e:
            config.logger.exception("Failed to add alert history: %s", e)

    return {
        "ok": True,
        "alert_sent": True,
        "reason": "sent",
        "sent_to": sent_to,
        "severity_score": round(severity_score, 1),
        "cooldown": cooldown,
    }


# ==============================
#   Scheduler Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹Ù‰
# ==============================

def weekly_scheduler_loop():
    """
    Scheduler Ø¯Ø§Ø®Ù„Ù‰:
    - ÙƒÙ„ 60 Ø«Ø§Ù†ÙŠØ© ÙŠØ´ÙŠÙƒ Ø§Ù„ÙŠÙˆÙ… / Ø§Ù„Ø³Ø§Ø¹Ø© (UTC).
    - Ù„Ùˆ Ø¬Ù…Ø¹Ø© 11:00 ÙˆÙ„Ø³Ù‡ Ù…Ø¨Ø¹ØªØ´ Ø§Ù„Ù†Ù‡Ø§Ø±Ø¯Ø© â†’ ÙŠØ¨Ø¹Øª Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹Ù‰.
    """
    config.logger.info("Weekly scheduler loop started.")
    while True:
        try:
            now = datetime.utcnow()
            config.LAST_WEEKLY_TICK = time.time()
            today_str = now.strftime("%Y-%m-%d")

            if now.weekday() == 4 and now.hour == 11:
                if config.LAST_WEEKLY_SENT_DATE != today_str:
                    config.logger.info("Weekly scheduler: sending weekly_ai_report automatically.")
                    send_weekly_report_to_all_chats()
                    config.LAST_WEEKLY_SENT_DATE = today_str
            time.sleep(60)
        except Exception as e:
            config.logger.exception("Error in weekly scheduler loop: %s", e)
            time.sleep(60)


# ==============================
#   Watchdog Ù…Ø¶Ø§Ø¯ Ù„Ù„ØªØ¬Ù…Ø¯
# ==============================

def watchdog_loop():
    """
    Anti-Freeze Watchdog:
    - ÙŠØ±Ø§Ù‚Ø¨:
        * Realtime engine
        * Weekly scheduler
        * webhook (Ù†Ø´Ø§Ø· ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù…)
    - Ù„Ùˆ tick Ù…ØªØ£Ø®Ø± Ø¬Ø¯Ù‹Ø§ â†’ ÙŠÙƒØªØ¨ ØªØ­Ø°ÙŠØ± ÙˆÙŠØ­Ø§ÙˆÙ„ ÙŠØ¹ÙŠØ¯ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø«Ø±ÙŠØ¯ Ù„Ùˆ Ù…Ø´ Ù…ÙˆØ¬ÙˆØ¯.
    """
    config.logger.info("Watchdog loop started.")
    while True:
        try:
            now = time.time()
            config.LAST_WATCHDOG_TICK = now

            # Realtime Engine monitoring
            rt_delta = now - (config.LAST_REALTIME_TICK or 0)
            if rt_delta > 30:
                config.logger.warning(
                    "Watchdog: realtime engine seems stalled (%.1f s).", rt_delta
                )
                if not any(t.name == "RealtimeEngine" for t in threading.enumerate()):
                    config.logger.warning("Watchdog: restarting realtime engine thread.")
                    start_realtime_thread()

            # Weekly Scheduler monitoring
            ws_delta = now - (config.LAST_WEEKLY_TICK or 0)
            if ws_delta > 300:  # 5 Ø¯Ù‚Ø§Ø¦Ù‚
                config.logger.warning(
                    "Watchdog: weekly scheduler seems stalled (%.1f s).", ws_delta
                )
                if not any(t.name == "WeeklyScheduler" for t in threading.enumerate()):
                    config.logger.warning("Watchdog: restarting weekly scheduler thread.")
                    start_weekly_scheduler_thread()

            # Webhook monitoring
            wh_delta = now - (config.LAST_WEBHOOK_TICK or 0)
            if config.LAST_WEBHOOK_TICK and wh_delta > 3600:
                config.logger.info(
                    "Watchdog: No webhook activity for %.1f seconds (might be normal at night).",
                    wh_delta,
                )

            time.sleep(5)
        except Exception as e:
            config.logger.exception("Error in watchdog loop: %s", e)
            time.sleep(5)


# ==============================
#   Ø¯ÙˆØ§Ù„ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø«Ø±ÙŠØ¯Ø§Øª
# ==============================

def start_realtime_thread():
    t_rt = threading.Thread(target=realtime_engine_loop, daemon=True, name="RealtimeEngine")
    t_rt.start()
    config.logger.info("Realtime engine thread started.")
    return t_rt


def start_weekly_scheduler_thread():
    t_weekly = threading.Thread(
        target=weekly_scheduler_loop, daemon=True, name="WeeklyScheduler"
    )
    t_weekly.start()
    config.logger.info("Weekly scheduler thread started.")
    return t_weekly


def start_watchdog_thread():
    t_wd = threading.Thread(target=watchdog_loop, daemon=True, name="Watchdog")
    t_wd.start()
    config.logger.info("Watchdog thread started.")
    return t_wd
